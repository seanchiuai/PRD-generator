import { NextRequest, NextResponse } from 'next/server'
import { anthropic, AI_MODELS, TOKEN_LIMITS } from "@/lib/ai-clients";
import {
  handleAPIError,
  handleValidationError,
  handleUnauthorizedError,
} from "@/lib/api-error-handler";
import { safeParseAIResponse } from "@/lib/parse-ai-json";
import { convexClient } from "@/lib/convex-client";
import { api } from '@/convex/_generated/api'
import { getDefaultTechStack, generateMockResearchResults } from '@/lib/techStack/defaults'
import { Id } from "@/convex/_generated/dataModel";
import { withAuth } from "@/lib/middleware/withAuth";

export const POST = withAuth(async (request, { userId }) => {
  try {
    const { conversationId, useAI = false } = await request.json()

    if (!conversationId) {
      return handleValidationError("Conversation ID required");
    }

    // Fetch conversation data
    const conversation = await convexClient.query(api.conversations.get, {
      conversationId: conversationId as Id<"conversations">,
    })

    if (!conversation) {
      return handleAPIError(
        new Error("Conversation not found"),
        "find conversation",
        404
      );
    }

    // Verify ownership
    if (conversation.userId !== userId) {
      return handleUnauthorizedError();
    }

    const extractedContext = conversation.extractedContext
    const clarifyingQuestions = conversation.clarifyingQuestions

    let techStack

    if (useAI && extractedContext) {
      // Use Claude for smarter suggestions
      techStack = await getAISuggestedStack(extractedContext, clarifyingQuestions)
    } else {
      // Use rule-based defaults
      techStack = getDefaultTechStack(extractedContext, clarifyingQuestions)
    }

    // Generate mock research results
    const researchResults = generateMockResearchResults(techStack)

    // Save to Convex
    await convexClient.mutation(api.conversations.saveResearchResults, {
      conversationId,
      results: researchResults,
      autoGenerated: true,
    })

    // Save selection
    await convexClient.mutation(api.conversations.saveSelection, {
      conversationId,
      selection: techStack,
      autoSelected: true,
    })

    // Validate the stack
    const validation = await validateDefaultStack(techStack)

    if (validation.errors.length > 0) {
      // If there are errors, try to fix them
      techStack = await fixStackErrors(techStack, validation.errors)

      // Re-save fixed selection
      await convexClient.mutation(api.conversations.saveSelection, {
        conversationId,
        selection: techStack,
        autoSelected: true,
      })
    }

    return NextResponse.json({
      success: true,
      techStack,
      validation,
    })
  } catch (error) {
    return handleAPIError(error, "generate default tech stack");
  }
});

async function getAISuggestedStack(extractedContext: any, answers: any) {
  const prompt = `
Suggest an optimal tech stack for this product:

PRODUCT CONTEXT:
${JSON.stringify(extractedContext, null, 2)}

ANSWERS:
${JSON.stringify(answers, null, 2)}

Based on this information, suggest:
1. Frontend framework/library
2. Backend framework/language
3. Database
4. Authentication solution
5. Hosting platform

Consider:
- Product type and scale
- Target audience
- Technical preferences mentioned
- Industry best practices
- Developer experience
- Cost-effectiveness

Return ONLY a JSON object:
{
  "frontend": "technology name",
  "backend": "technology name",
  "database": "technology name",
  "auth": "technology name",
  "hosting": "technology name"
}
`

  const response = await anthropic.messages.create({
    model: AI_MODELS.CLAUDE_SONNET,
    max_tokens: TOKEN_LIMITS.TECH_STACK,
    temperature: 0.3,
    messages: [{ role: 'user', content: prompt }],
  })

  const textContent = response.content.find((block) => block.type === 'text')
  if (!textContent || textContent.type !== 'text') {
    throw new Error('Unexpected response type from Claude')
  }

  interface TechStack {
    frontend: string;
    backend: string;
    database: string;
    auth: string;
    hosting: string;
  }

  return safeParseAIResponse<TechStack>(textContent.text) || getDefaultTechStack(extractedContext, answers)
}

async function validateDefaultStack(_stack: any) {
  // Basic validation - could be enhanced
  return {
    isValid: true,
    errors: [],
    warnings: [],
  }
}

async function fixStackErrors(_stack: any, _errors: any[]) {
  // If there are compatibility errors, fall back to safest defaults
  return {
    frontend: 'Next.js',
    backend: 'Node.js with Express',
    database: 'PostgreSQL',
    auth: 'Clerk',
    hosting: 'Vercel',
  }
}
